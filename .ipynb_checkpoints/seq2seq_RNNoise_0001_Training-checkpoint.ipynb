{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-07-17 17:23:24--  http://210.89.182.185:7070/coda/GM12878.npz\n",
      "Connecting to 210.89.182.185:7070... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75677131 (72M) [application/octet-stream]\n",
      "Saving to: ‘GM12878.npz.1’\n",
      "\n",
      "GM12878.npz.1       100%[===================>]  72.17M   123MB/s    in 0.6s    \n",
      "\n",
      "2018-07-17 17:23:25 (123 MB/s) - ‘GM12878.npz.1’ saved [75677131/75677131]\n",
      "\n",
      "--2018-07-17 17:23:25--  http://210.89.182.185:7070/coda/GM18526.npz\n",
      "Connecting to 210.89.182.185:7070... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 73302701 (70M) [application/octet-stream]\n",
      "Saving to: ‘GM18526.npz.1’\n",
      "\n",
      "GM18526.npz.1       100%[===================>]  69.91M  82.8MB/s    in 0.8s    \n",
      "\n",
      "2018-07-17 17:23:26 (82.8 MB/s) - ‘GM18526.npz.1’ saved [73302701/73302701]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!pip install keras==2.1.6\n",
    "#!wget http://210.89.182.185:7070/coda/GM12878.npz\n",
    "#!wget http://210.89.182.185:7070/coda/GM18526.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_MARKS  = [\"H3K27AC\", \"H3K27ME3\", \"H3K36ME3\", \"H3K4ME1\", \"H3K4ME3\", \"INPUT\"]\n",
    "OUTPUT_MARKS = [\"H3K27AC\"]\n",
    "MARK_INDEX   = [0, 1, 2, 3, 4, 5]\n",
    "PEAK_MARK_INDEX = [0, 1, 2, 3, 4]\n",
    "SEQ_LENGTH = 1001\n",
    "#DATA_PATH = './data/GM12878_5+1marks-K4me3_all_subsample-0.5e6-None_rS-0_numEx-1000_seqLen-1001_peakFrac-0.5_peaksFac-H3K27AC_norm-arcsinh.npz'\n",
    "DATA_PATH = 'GM12878.npz'\n",
    "EVAL_PATH = 'GM18526.npz'\n",
    "zero_out_non_bins = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "def input_not_before_end(list_of_marks):\n",
    "    return ('INPUT' not in list_of_marks[:-1])\n",
    "\n",
    "def load_seq_dataset():\n",
    "    seq_length = SEQ_LENGTH\n",
    "    input_marks = INPUT_MARKS\n",
    "    output_marks = OUTPUT_MARKS\n",
    "  \n",
    "    assert(input_not_before_end(output_marks))\n",
    "    assert(input_not_before_end(input_marks))\n",
    "    \n",
    "    dataset_path = os.path.join(DATA_PATH)\n",
    "\n",
    "    #try:      \n",
    "    with np.load(dataset_path) as data:\n",
    "        X = data['X'].astype('float32')\n",
    "        Y = data['Y'].astype('float32')\n",
    "        peakPValueX = data['peakPValueX'].astype('float32')\n",
    "        peakPValueY = data['peakPValueY'].astype('float32')\n",
    "        peakBinaryX = data['peakBinaryX'].astype('int8')\n",
    "        peakBinaryY = data['peakBinaryY'].astype('int8')\n",
    "    #except:\n",
    "        #raise Exception, \"Dataset doesn't exist or is missing a required matrix.\"\n",
    "\n",
    "    \n",
    "    marks_idx =  MARK_INDEX\n",
    "    peak_marks_idx = PEAK_MARK_INDEX\n",
    "    \n",
    "    X = X[..., marks_idx]\n",
    "    peakPValueX = peakPValueX[..., peak_marks_idx]\n",
    "    peakBinaryX = peakBinaryX[..., peak_marks_idx]\n",
    "\n",
    "    assert(np.all(peakPValueX >= 0) & np.all(peakPValueY >= 0))\n",
    "\n",
    "    if (X.shape[0], X.shape[1]) != (Y.shape[0], Y.shape[1]):\n",
    "        raise Exception(\"First two dimensions of X and Y shapes (num_examples, seq_length) \\\n",
    "                          need to agree.\")\n",
    "    if (peakPValueX.shape[0], peakPValueX.shape[1]) != (peakPValueY.shape[0], peakPValueY.shape[1]):\n",
    "        raise Exception(\"First two dimensions of peakPValueX and peakPValueY shapes \\\n",
    "                          (num_examples, seq_length) need to agree.\")\n",
    "    if len(peakPValueX) != len(X):\n",
    "        raise Exception(\"peakPValueX and X must have same length.\")\n",
    "\n",
    "    if ((seq_length != X.shape[1]) or (seq_length != peakPValueX.shape[1])):\n",
    "        raise Exception(\"seq_length between model and data needs to agree\")\n",
    "\n",
    "    return X, Y, peakPValueX, peakPValueY, peakBinaryX, peakBinaryY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataNormalizer(object):\n",
    "    def __init__(self, mode):\n",
    "        self.b = None\n",
    "        self.W = None\n",
    "        self.mode = mode\n",
    "        if mode not in ['ZCA', 'Z', '01', 'identity']:\n",
    "            raise ValueError(\"mode=%s must be 'ZCA', 'Z', '01', or 'identity'\" % mode)\n",
    "\n",
    "\n",
    "    def fit(self, X_orig):\n",
    "        \"\"\"\n",
    "        Learns scaling parameters on the X_orig dataset. Does not modify X_orig.\n",
    "        \"\"\"        \n",
    "        if len(X_orig.shape) != 2 and len(X_orig.shape) != 3:\n",
    "            raise ValueError(\"X must be either a 3-tensor of shape num_examples x seq_length x \\\n",
    "                               num_input_marks, or a 2-tensor of shape num_examples x num_input_marks\")\n",
    "        if self.mode == 'identity':\n",
    "            return None        \n",
    "\n",
    "        X = np.copy(X_orig)\n",
    "        num_input_marks = X.shape[-1]\n",
    "\n",
    "        # If X is a 3-tensor, reshape X such that it is a 2-tensor of shape \n",
    "        # (num_examples * seq_length) x num_input_marks. \n",
    "        if len(X.shape) == 3:    \n",
    "            X = np.reshape(X, (-1, num_input_marks))\n",
    "        \n",
    "        self.b = np.mean(X, axis=0) \n",
    "\n",
    "        X -= self.b\n",
    "\n",
    "        if self.mode == 'ZCA':\n",
    "            sigma = np.dot(X.T, X) / X.shape[0]\n",
    "            U, S, V = np.linalg.svd(sigma)\n",
    "            self.W = np.dot(\n",
    "                np.dot(U, np.diag(1 / np.sqrt(S + 1e-5))),\n",
    "                U.T)\n",
    "        elif self.mode == 'Z':\n",
    "            self.W = np.empty(num_input_marks)\n",
    "            for idx in range(num_input_marks):\n",
    "                self.W[idx] = np.std(X[:, idx])\n",
    "        elif self.mode == '01':\n",
    "            self.W = np.empty(num_input_marks)\n",
    "            for idx in range(num_input_marks):\n",
    "                self.W[idx] = np.max(np.abs(X[:, idx]))\n",
    "\n",
    "        return None            \n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        if len(X.shape) != 2 and len(X.shape) != 3:\n",
    "            raise ValueError(\"X must be either a 3-tensor of shape num_examples x seq_length x \\\n",
    "                               num_input_marks, or a 2-tensor of shape num_examples x num_input_marks\")\n",
    "\n",
    "        if self.mode == 'identity':\n",
    "            return X\n",
    "            \n",
    "        assert self.b is not None\n",
    "        assert self.W is not None\n",
    "\n",
    "        num_input_marks = X.shape[-1]\n",
    "        orig_shape = X.shape\n",
    "\n",
    "        if self.mode == 'ZCA':            \n",
    "            X = np.reshape(X, (-1, num_input_marks))\n",
    "            if self.W.shape[1] != X.shape[1]:\n",
    "                raise ValueError(\"When doing a ZCA transform, X and W must have the same number of columns.\")\n",
    "            X = np.dot(\n",
    "                X - self.b,\n",
    "                self.W.T)\n",
    "            X = np.reshape(X, orig_shape)\n",
    "        elif self.mode in ['Z', '01']:\n",
    "            if (len(self.b) != num_input_marks) or (len(self.W) != num_input_marks):\n",
    "                print(\"X.shape: \", X.shape)\n",
    "                print(\"b.shape: \", self.b.shape)\n",
    "                print(\"W.shape: \", self.W.shape)\n",
    "                raise ValueError(\"The shapes of X, b, and W must all share the same last dimension.\")                \n",
    "            for idx in range(num_input_marks):\n",
    "                X[..., idx] = (X[..., idx] - self.b[idx]) / self.W[idx]\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, peakPValueX, peakPValueY, peakBinaryX, peakBinaryY = load_seq_dataset()\n",
    "\n",
    "if zero_out_non_bins:\n",
    "    peakPValueX = peakPValueX * peakBinaryX\n",
    "    peakPValueY = peakPValueY * peakBinaryY \n",
    "\n",
    "def sq2p_process_X(X):\n",
    "    return X\n",
    "\n",
    "def sq2p_process_Y(Y):\n",
    "    '''mid = (SEQ_LENGTH - 1) / 2\n",
    "    mid = int(mid)\n",
    "    return Y[:, mid:mid+1, :]'''\n",
    "    return Y\n",
    "    \n",
    "    \n",
    "X = sq2p_process_X(X)\n",
    "Y = sq2p_process_Y(Y)\n",
    "peakPValueX = sq2p_process_X(peakPValueX)\n",
    "peakPValueY = sq2p_process_Y(peakPValueY)\n",
    "peakBinaryX = sq2p_process_X(peakBinaryX)\n",
    "peakBinaryY = sq2p_process_Y(peakBinaryY)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_input = \"01\"\n",
    "normalizer = DataNormalizer(scale_input)\n",
    "normalizer.fit(X)\n",
    "X = normalizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCH          = 10\n",
    "VALID_SPLIT       = 0.05\n",
    "BATCH_SIZE        = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "seq2point_weight_bin = 's2q-rnn'\n",
    "bin_checkpointer = ModelCheckpoint(\n",
    "    filepath=os.path.join('.', '%s-weights.hdf5'%seq2point_weight_bin), \n",
    "    verbose=1, \n",
    "    save_best_only=True)\n",
    "\n",
    "bin_earlystopper = EarlyStopping(monitor='val_loss', patience=3, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "from keras import losses\n",
    "from keras import regularizers\n",
    "from keras.constraints import min_max_norm\n",
    "from keras.constraints import Constraint\n",
    "from keras import backend as K\n",
    "def rnn_model():\n",
    "    main_input = Input(shape=(SEQ_LENGTH, len(INPUT_MARKS)), name='main_input')\n",
    "    # Noise Spectral Estimation\n",
    "    noise_gru = GRU(\n",
    "      48, \n",
    "      activation='relu', \n",
    "      recurrent_activation='sigmoid', \n",
    "      return_sequences=True, \n",
    "      name='noise_gru'\n",
    "    )(main_input)\n",
    "\n",
    "    # Spectral Subtraction\n",
    "    denoise_input = keras.layers.concatenate([noise_gru, main_input])\n",
    "    denoise_gru = GRU(\n",
    "      96, \n",
    "      activation='relu', \n",
    "      recurrent_activation='sigmoid', \n",
    "      return_sequences=True, \n",
    "      name='denoise_gru'\n",
    "    )(denoise_input)\n",
    "        \n",
    "    denoise_output = Dense(\n",
    "      1, \n",
    "      activation='relu', \n",
    "      name='denoise_output'\n",
    "    )(denoise_gru)\n",
    "    \n",
    "    '''\n",
    "    denoise_output = keras.layers.Conv1D(\n",
    "        filters=len(OUTPUT_MARKS),\n",
    "        kernel_size=SEQ_LENGTH,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        activation='relu'\n",
    "    )(denoise_dense)\n",
    "    '''\n",
    "\n",
    "    # Peak ? Nope\n",
    "    peak_input = keras.layers.concatenate([denoise_gru, main_input])  \n",
    "\n",
    "    peak_gru = GRU(\n",
    "      24, \n",
    "      activation='relu', \n",
    "      recurrent_activation='sigmoid', \n",
    "      return_sequences=True, \n",
    "      name='peak_gru'\n",
    "    )(peak_input)\n",
    "    \n",
    "    peak_output = Dense(\n",
    "      1, \n",
    "      activation='sigmoid', \n",
    "      name='peak_output'\n",
    "    )(peak_gru)\n",
    "    '''\n",
    "    peak_output = keras.layers.Conv1D(\n",
    "        filters=len(OUTPUT_MARKS),\n",
    "        kernel_size=SEQ_LENGTH,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        activation='sigmoid'\n",
    "    )(peak_dense)\n",
    "    '''\n",
    "\n",
    "    model = Model(inputs=main_input, outputs=[denoise_output, peak_output])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 1001, 6)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "noise_gru (GRU)                 (None, 1001, 48)     7920        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1001, 54)     0           noise_gru[0][0]                  \n",
      "                                                                 main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "denoise_gru (GRU)               (None, 1001, 96)     43488       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1001, 102)    0           denoise_gru[0][0]                \n",
      "                                                                 main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "peak_gru (GRU)                  (None, 1001, 24)     9144        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "denoise_output (Dense)          (None, 1001, 1)      97          denoise_gru[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "peak_output (Dense)             (None, 1001, 1)      25          peak_gru[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 60,674\n",
      "Trainable params: 60,674\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model = rnn_model()\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(loss=[losses.mean_squared_error, losses.binary_crossentropy],\n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-shape: (10000, 1001, 6)\n",
      "Y-shape: (10000, 1001, 1)\n",
      "pY-shape: (10000, 1001, 1)\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 234s 25ms/step - loss: 1.1551 - denoise_output_loss: 0.7095 - peak_output_loss: 0.4456 - val_loss: 0.5040 - val_denoise_output_loss: 0.3145 - val_peak_output_loss: 0.1895\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.50396, saving model to ./s2q-rnn-weights.hdf5\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 232s 24ms/step - loss: 0.4521 - denoise_output_loss: 0.2801 - peak_output_loss: 0.1720 - val_loss: 0.4441 - val_denoise_output_loss: 0.2669 - val_peak_output_loss: 0.1772\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.50396 to 0.44411, saving model to ./s2q-rnn-weights.hdf5\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 227s 24ms/step - loss: 0.4285 - denoise_output_loss: 0.2599 - peak_output_loss: 0.1685 - val_loss: 0.4349 - val_denoise_output_loss: 0.2590 - val_peak_output_loss: 0.1759\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.44411 to 0.43494, saving model to ./s2q-rnn-weights.hdf5\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 222s 23ms/step - loss: 0.4192 - denoise_output_loss: 0.2524 - peak_output_loss: 0.1667 - val_loss: 0.4280 - val_denoise_output_loss: 0.2526 - val_peak_output_loss: 0.1754\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.43494 to 0.42800, saving model to ./s2q-rnn-weights.hdf5\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 221s 23ms/step - loss: 0.4096 - denoise_output_loss: 0.2442 - peak_output_loss: 0.1654 - val_loss: 0.4179 - val_denoise_output_loss: 0.2438 - val_peak_output_loss: 0.1741\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.42800 to 0.41792, saving model to ./s2q-rnn-weights.hdf5\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 222s 23ms/step - loss: 0.4038 - denoise_output_loss: 0.2390 - peak_output_loss: 0.1648 - val_loss: 0.4100 - val_denoise_output_loss: 0.2374 - val_peak_output_loss: 0.1727\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.41792 to 0.41004, saving model to ./s2q-rnn-weights.hdf5\n",
      "Epoch 7/10\n",
      "9500/9500 [==============================] - 223s 23ms/step - loss: 0.3977 - denoise_output_loss: 0.2340 - peak_output_loss: 0.1637 - val_loss: 0.4115 - val_denoise_output_loss: 0.2392 - val_peak_output_loss: 0.1723\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.41004\n",
      "Epoch 8/10\n",
      "9500/9500 [==============================] - 223s 23ms/step - loss: 0.3908 - denoise_output_loss: 0.2286 - peak_output_loss: 0.1623 - val_loss: 0.4036 - val_denoise_output_loss: 0.2327 - val_peak_output_loss: 0.1709\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.41004 to 0.40358, saving model to ./s2q-rnn-weights.hdf5\n",
      "Epoch 9/10\n",
      "9500/9500 [==============================] - 223s 23ms/step - loss: 0.3874 - denoise_output_loss: 0.2257 - peak_output_loss: 0.1616 - val_loss: 0.3979 - val_denoise_output_loss: 0.2268 - val_peak_output_loss: 0.1710\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.40358 to 0.39786, saving model to ./s2q-rnn-weights.hdf5\n",
      "Epoch 10/10\n",
      "7300/9500 [======================>.......] - ETA: 50s - loss: 0.3871 - denoise_output_loss: 0.2247 - peak_output_loss: 0.1625"
     ]
    }
   ],
   "source": [
    "print('X-shape:',X.shape)\n",
    "print('Y-shape:',Y.shape)\n",
    "print('pY-shape:',peakBinaryY.shape)\n",
    "\n",
    "rnn_model.fit(X, [Y, peakBinaryY], \n",
    "             callbacks=[bin_checkpointer, bin_earlystopper],\n",
    "             epochs=NB_EPOCH,\n",
    "             validation_split=VALID_SPLIT,\n",
    "             batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
