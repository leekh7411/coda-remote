{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras==2.1.6\n",
    "#!wget http://210.89.182.185:7070/coda/GM12878.npz\n",
    "#!wget http://210.89.182.185:7070/coda/GM18526.npz\n",
    "weights_file_name = 's2s-rnn-0003'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_MARKS  = [\"H3K27AC\", \"H3K27ME3\", \"H3K36ME3\", \"H3K4ME1\", \"H3K4ME3\", \"INPUT\"]\n",
    "OUTPUT_MARKS = [\"H3K27AC\"]\n",
    "MARK_INDEX   = [0, 1, 2, 3, 4, 5]\n",
    "PEAK_MARK_INDEX = [0, 1, 2, 3, 4]\n",
    "SEQ_LENGTH = 1001\n",
    "#DATA_PATH = './data/GM12878_5+1marks-K4me3_all_subsample-0.5e6-None_rS-0_numEx-1000_seqLen-1001_peakFrac-0.5_peaksFac-H3K27AC_norm-arcsinh.npz'\n",
    "DATA_PATH = 'GM12878.npz'\n",
    "EVAL_PATH = 'GM18526.npz'\n",
    "zero_out_non_bins = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "def input_not_before_end(list_of_marks):\n",
    "    return ('INPUT' not in list_of_marks[:-1])\n",
    "\n",
    "def load_seq_dataset():\n",
    "    seq_length = SEQ_LENGTH\n",
    "    input_marks = INPUT_MARKS\n",
    "    output_marks = OUTPUT_MARKS\n",
    "  \n",
    "    assert(input_not_before_end(output_marks))\n",
    "    assert(input_not_before_end(input_marks))\n",
    "    \n",
    "    dataset_path = os.path.join(DATA_PATH)\n",
    "\n",
    "    #try:      \n",
    "    with np.load(dataset_path) as data:\n",
    "        X = data['X'].astype('float32')\n",
    "        Y = data['Y'].astype('float32')\n",
    "        peakPValueX = data['peakPValueX'].astype('float32')\n",
    "        peakPValueY = data['peakPValueY'].astype('float32')\n",
    "        peakBinaryX = data['peakBinaryX'].astype('int8')\n",
    "        peakBinaryY = data['peakBinaryY'].astype('int8')\n",
    "    #except:\n",
    "        #raise Exception, \"Dataset doesn't exist or is missing a required matrix.\"\n",
    "\n",
    "    \n",
    "    marks_idx =  MARK_INDEX\n",
    "    peak_marks_idx = PEAK_MARK_INDEX\n",
    "    \n",
    "    X = X[..., marks_idx]\n",
    "    peakPValueX = peakPValueX[..., peak_marks_idx]\n",
    "    peakBinaryX = peakBinaryX[..., peak_marks_idx]\n",
    "\n",
    "    assert(np.all(peakPValueX >= 0) & np.all(peakPValueY >= 0))\n",
    "\n",
    "    if (X.shape[0], X.shape[1]) != (Y.shape[0], Y.shape[1]):\n",
    "        raise Exception(\"First two dimensions of X and Y shapes (num_examples, seq_length) \\\n",
    "                          need to agree.\")\n",
    "    if (peakPValueX.shape[0], peakPValueX.shape[1]) != (peakPValueY.shape[0], peakPValueY.shape[1]):\n",
    "        raise Exception(\"First two dimensions of peakPValueX and peakPValueY shapes \\\n",
    "                          (num_examples, seq_length) need to agree.\")\n",
    "    if len(peakPValueX) != len(X):\n",
    "        raise Exception(\"peakPValueX and X must have same length.\")\n",
    "\n",
    "    if ((seq_length != X.shape[1]) or (seq_length != peakPValueX.shape[1])):\n",
    "        raise Exception(\"seq_length between model and data needs to agree\")\n",
    "\n",
    "    return X, Y, peakPValueX, peakPValueY, peakBinaryX, peakBinaryY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataNormalizer(object):\n",
    "    def __init__(self, mode):\n",
    "        self.b = None\n",
    "        self.W = None\n",
    "        self.mode = mode\n",
    "        if mode not in ['ZCA', 'Z', '01', 'identity']:\n",
    "            raise ValueError(\"mode=%s must be 'ZCA', 'Z', '01', or 'identity'\" % mode)\n",
    "\n",
    "\n",
    "    def fit(self, X_orig):\n",
    "        \"\"\"\n",
    "        Learns scaling parameters on the X_orig dataset. Does not modify X_orig.\n",
    "        \"\"\"        \n",
    "        if len(X_orig.shape) != 2 and len(X_orig.shape) != 3:\n",
    "            raise ValueError(\"X must be either a 3-tensor of shape num_examples x seq_length x \\\n",
    "                               num_input_marks, or a 2-tensor of shape num_examples x num_input_marks\")\n",
    "        if self.mode == 'identity':\n",
    "            return None        \n",
    "\n",
    "        X = np.copy(X_orig)\n",
    "        num_input_marks = X.shape[-1]\n",
    "\n",
    "        # If X is a 3-tensor, reshape X such that it is a 2-tensor of shape \n",
    "        # (num_examples * seq_length) x num_input_marks. \n",
    "        if len(X.shape) == 3:    \n",
    "            X = np.reshape(X, (-1, num_input_marks))\n",
    "        \n",
    "        self.b = np.mean(X, axis=0) \n",
    "\n",
    "        X -= self.b\n",
    "\n",
    "        if self.mode == 'ZCA':\n",
    "            sigma = np.dot(X.T, X) / X.shape[0]\n",
    "            U, S, V = np.linalg.svd(sigma)\n",
    "            self.W = np.dot(\n",
    "                np.dot(U, np.diag(1 / np.sqrt(S + 1e-5))),\n",
    "                U.T)\n",
    "        elif self.mode == 'Z':\n",
    "            self.W = np.empty(num_input_marks)\n",
    "            for idx in range(num_input_marks):\n",
    "                self.W[idx] = np.std(X[:, idx])\n",
    "        elif self.mode == '01':\n",
    "            self.W = np.empty(num_input_marks)\n",
    "            for idx in range(num_input_marks):\n",
    "                self.W[idx] = np.max(np.abs(X[:, idx]))\n",
    "\n",
    "        return None            \n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        if len(X.shape) != 2 and len(X.shape) != 3:\n",
    "            raise ValueError(\"X must be either a 3-tensor of shape num_examples x seq_length x \\\n",
    "                               num_input_marks, or a 2-tensor of shape num_examples x num_input_marks\")\n",
    "\n",
    "        if self.mode == 'identity':\n",
    "            return X\n",
    "            \n",
    "        assert self.b is not None\n",
    "        assert self.W is not None\n",
    "\n",
    "        num_input_marks = X.shape[-1]\n",
    "        orig_shape = X.shape\n",
    "\n",
    "        if self.mode == 'ZCA':            \n",
    "            X = np.reshape(X, (-1, num_input_marks))\n",
    "            if self.W.shape[1] != X.shape[1]:\n",
    "                raise ValueError(\"When doing a ZCA transform, X and W must have the same number of columns.\")\n",
    "            X = np.dot(\n",
    "                X - self.b,\n",
    "                self.W.T)\n",
    "            X = np.reshape(X, orig_shape)\n",
    "        elif self.mode in ['Z', '01']:\n",
    "            if (len(self.b) != num_input_marks) or (len(self.W) != num_input_marks):\n",
    "                print(\"X.shape: \", X.shape)\n",
    "                print(\"b.shape: \", self.b.shape)\n",
    "                print(\"W.shape: \", self.W.shape)\n",
    "                raise ValueError(\"The shapes of X, b, and W must all share the same last dimension.\")                \n",
    "            for idx in range(num_input_marks):\n",
    "                X[..., idx] = (X[..., idx] - self.b[idx]) / self.W[idx]\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, peakPValueX, peakPValueY, peakBinaryX, peakBinaryY = load_seq_dataset()\n",
    "\n",
    "if zero_out_non_bins:\n",
    "    peakPValueX = peakPValueX * peakBinaryX\n",
    "    peakPValueY = peakPValueY * peakBinaryY \n",
    "\n",
    "def sq2p_process_X(X):\n",
    "    return X\n",
    "\n",
    "def sq2p_process_Y(Y):\n",
    "    '''mid = (SEQ_LENGTH - 1) / 2\n",
    "    mid = int(mid)\n",
    "    return Y[:, mid:mid+1, :]'''\n",
    "    return Y\n",
    "    \n",
    "    \n",
    "X = sq2p_process_X(X)\n",
    "Y = sq2p_process_Y(Y)\n",
    "peakPValueX = sq2p_process_X(peakPValueX)\n",
    "peakPValueY = sq2p_process_Y(peakPValueY)\n",
    "peakBinaryX = sq2p_process_X(peakBinaryX)\n",
    "peakBinaryY = sq2p_process_Y(peakBinaryY)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_input = \"01\"\n",
    "normalizer = DataNormalizer(scale_input)\n",
    "normalizer.fit(X)\n",
    "X = normalizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCH          = 10\n",
    "VALID_SPLIT       = 0.05\n",
    "BATCH_SIZE        = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "bin_checkpointer = ModelCheckpoint(\n",
    "    filepath=os.path.join('.', '%s-weights.hdf5'%weights_file_name), \n",
    "    verbose=1, \n",
    "    save_best_only=True)\n",
    "\n",
    "bin_earlystopper = EarlyStopping(monitor='val_loss', patience=3, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "from keras import losses\n",
    "from keras import regularizers\n",
    "from keras.constraints import min_max_norm\n",
    "from keras.constraints import Constraint\n",
    "from keras import backend as K\n",
    "def rnn_model():\n",
    "    main_input = Input(shape=(SEQ_LENGTH, len(INPUT_MARKS)), name='main_input')\n",
    "    # Noise Spectral Estimation\n",
    "    noise_gru = GRU(\n",
    "      22, \n",
    "      activation='tanh', \n",
    "      recurrent_activation='sigmoid', \n",
    "      return_sequences=True, \n",
    "      name='noise_gru'\n",
    "    )(main_input)\n",
    "    \n",
    "    noise_cnn = keras.layers.Conv1D(\n",
    "        filters=12,\n",
    "        kernel_size=16,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        activation='tanh'\n",
    "    )(noise_gru)\n",
    "    \n",
    "\n",
    "    # Spectral Subtraction\n",
    "    denoise_input = keras.layers.concatenate([noise_gru, noise_cnn ,main_input])\n",
    "    denoise_gru = GRU(\n",
    "      24, \n",
    "      activation='tanh', \n",
    "      recurrent_activation='sigmoid', \n",
    "      return_sequences=True, \n",
    "      name='denoise_gru'\n",
    "    )(denoise_input)\n",
    "    \n",
    "    denoise_cnn = keras.layers.Conv1D(\n",
    "        filters=16,\n",
    "        kernel_size=24,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        activation='tanh'\n",
    "    )(denoise_gru)\n",
    "     \n",
    "    denoise_output = Dense(\n",
    "      1, \n",
    "      activation='relu', \n",
    "      name='denoise_output'\n",
    "    )(denoise_cnn)\n",
    "    \n",
    "    '''\n",
    "    denoise_output = keras.layers.Conv1D(\n",
    "        filters=len(OUTPUT_MARKS),\n",
    "        kernel_size=SEQ_LENGTH,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        activation='relu'\n",
    "    )(denoise_dense)\n",
    "    '''\n",
    "\n",
    "    # Peak ? Nope\n",
    "    peak_input = keras.layers.concatenate([denoise_gru, denoise_cnn, main_input])  \n",
    "\n",
    "    peak_gru = GRU(\n",
    "      24, \n",
    "      activation='tanh', \n",
    "      recurrent_activation='sigmoid', \n",
    "      return_sequences=True, \n",
    "      name='peak_gru'\n",
    "    )(peak_input)\n",
    "    \n",
    "    peak_cnn = keras.layers.Conv1D(\n",
    "        filters=16,\n",
    "        kernel_size=24,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        activation='tanh'\n",
    "    )(peak_gru)\n",
    "       \n",
    "    peak_output = Dense(\n",
    "      1, \n",
    "      activation='sigmoid', \n",
    "      name='peak_output'\n",
    "    )(peak_cnn)\n",
    "    '''\n",
    "    peak_output = keras.layers.Conv1D(\n",
    "        filters=len(OUTPUT_MARKS),\n",
    "        kernel_size=SEQ_LENGTH,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        activation='sigmoid'\n",
    "    )(peak_dense)\n",
    "    '''\n",
    "\n",
    "    model = Model(inputs=main_input, outputs=[denoise_output, peak_output])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ncp/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 1001, 6)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "noise_gru (GRU)                 (None, 1001, 22)     1914        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1001, 12)     4236        noise_gru[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1001, 40)     0           noise_gru[0][0]                  \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "                                                                 main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "denoise_gru (GRU)               (None, 1001, 24)     4680        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1001, 16)     9232        denoise_gru[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1001, 46)     0           denoise_gru[0][0]                \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "                                                                 main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "peak_gru (GRU)                  (None, 1001, 24)     5112        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1001, 16)     9232        peak_gru[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "denoise_output (Dense)          (None, 1001, 1)      17          conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "peak_output (Dense)             (None, 1001, 1)      17          conv1d_3[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 34,440\n",
      "Trainable params: 34,440\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model = rnn_model()\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(loss=[losses.mean_squared_error, losses.binary_crossentropy],\n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-shape: (10000, 1001, 6)\n",
      "Y-shape: (10000, 1001, 1)\n",
      "pY-shape: (10000, 1001, 1)\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 242s 25ms/step - loss: 0.7000 - denoise_output_loss: 0.4752 - peak_output_loss: 0.2248 - val_loss: 0.4437 - val_denoise_output_loss: 0.2793 - val_peak_output_loss: 0.1644\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.44371, saving model to ./s2s-rnn-0003-weights.hdf5\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 236s 25ms/step - loss: 0.3873 - denoise_output_loss: 0.2392 - peak_output_loss: 0.1481 - val_loss: 0.3824 - val_denoise_output_loss: 0.2258 - val_peak_output_loss: 0.1566\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.44371 to 0.38243, saving model to ./s2s-rnn-0003-weights.hdf5\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 232s 24ms/step - loss: 0.3537 - denoise_output_loss: 0.2121 - peak_output_loss: 0.1415 - val_loss: 0.3612 - val_denoise_output_loss: 0.2123 - val_peak_output_loss: 0.1489\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.38243 to 0.36120, saving model to ./s2s-rnn-0003-weights.hdf5\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 229s 24ms/step - loss: 0.3408 - denoise_output_loss: 0.2024 - peak_output_loss: 0.1384 - val_loss: 0.3512 - val_denoise_output_loss: 0.2046 - val_peak_output_loss: 0.1466\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.36120 to 0.35122, saving model to ./s2s-rnn-0003-weights.hdf5\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 231s 24ms/step - loss: 0.3304 - denoise_output_loss: 0.1942 - peak_output_loss: 0.1362 - val_loss: 0.3534 - val_denoise_output_loss: 0.2087 - val_peak_output_loss: 0.1447\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.35122\n",
      "Epoch 6/10\n",
      " 500/9500 [>.............................] - ETA: 3:39 - loss: 0.3143 - denoise_output_loss: 0.1862 - peak_output_loss: 0.1281"
     ]
    }
   ],
   "source": [
    "print('X-shape:',X.shape)\n",
    "print('Y-shape:',Y.shape)\n",
    "print('pY-shape:',peakBinaryY.shape)\n",
    "\n",
    "rnn_model.fit(X, [Y, peakBinaryY], \n",
    "             callbacks=[bin_checkpointer, bin_earlystopper],\n",
    "             epochs=NB_EPOCH,\n",
    "             validation_split=VALID_SPLIT,\n",
    "             batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
