{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras==2.1.6\n",
    "#!wget http://210.89.182.185:7070/coda/GM12878.npz\n",
    "#!wget http://210.89.182.185:7070/coda/GM18526.npz\n",
    "weights_file_name = 's2s-rnn-0002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_MARKS  = [\"H3K27AC\", \"H3K27ME3\", \"H3K36ME3\", \"H3K4ME1\", \"H3K4ME3\", \"INPUT\"]\n",
    "OUTPUT_MARKS = [\"H3K27AC\"]\n",
    "MARK_INDEX   = [0, 1, 2, 3, 4, 5]\n",
    "PEAK_MARK_INDEX = [0, 1, 2, 3, 4]\n",
    "SEQ_LENGTH = 1001\n",
    "#DATA_PATH = './data/GM12878_5+1marks-K4me3_all_subsample-0.5e6-None_rS-0_numEx-1000_seqLen-1001_peakFrac-0.5_peaksFac-H3K27AC_norm-arcsinh.npz'\n",
    "DATA_PATH = 'GM12878.npz'\n",
    "EVAL_PATH = 'GM18526.npz'\n",
    "zero_out_non_bins = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "def input_not_before_end(list_of_marks):\n",
    "    return ('INPUT' not in list_of_marks[:-1])\n",
    "\n",
    "def load_seq_dataset():\n",
    "    seq_length = SEQ_LENGTH\n",
    "    input_marks = INPUT_MARKS\n",
    "    output_marks = OUTPUT_MARKS\n",
    "  \n",
    "    assert(input_not_before_end(output_marks))\n",
    "    assert(input_not_before_end(input_marks))\n",
    "    \n",
    "    dataset_path = os.path.join(DATA_PATH)\n",
    "\n",
    "    #try:      \n",
    "    with np.load(dataset_path) as data:\n",
    "        X = data['X'].astype('float32')\n",
    "        Y = data['Y'].astype('float32')\n",
    "        peakPValueX = data['peakPValueX'].astype('float32')\n",
    "        peakPValueY = data['peakPValueY'].astype('float32')\n",
    "        peakBinaryX = data['peakBinaryX'].astype('int8')\n",
    "        peakBinaryY = data['peakBinaryY'].astype('int8')\n",
    "    #except:\n",
    "        #raise Exception, \"Dataset doesn't exist or is missing a required matrix.\"\n",
    "\n",
    "    \n",
    "    marks_idx =  MARK_INDEX\n",
    "    peak_marks_idx = PEAK_MARK_INDEX\n",
    "    \n",
    "    X = X[..., marks_idx]\n",
    "    peakPValueX = peakPValueX[..., peak_marks_idx]\n",
    "    peakBinaryX = peakBinaryX[..., peak_marks_idx]\n",
    "\n",
    "    assert(np.all(peakPValueX >= 0) & np.all(peakPValueY >= 0))\n",
    "\n",
    "    if (X.shape[0], X.shape[1]) != (Y.shape[0], Y.shape[1]):\n",
    "        raise Exception(\"First two dimensions of X and Y shapes (num_examples, seq_length) \\\n",
    "                          need to agree.\")\n",
    "    if (peakPValueX.shape[0], peakPValueX.shape[1]) != (peakPValueY.shape[0], peakPValueY.shape[1]):\n",
    "        raise Exception(\"First two dimensions of peakPValueX and peakPValueY shapes \\\n",
    "                          (num_examples, seq_length) need to agree.\")\n",
    "    if len(peakPValueX) != len(X):\n",
    "        raise Exception(\"peakPValueX and X must have same length.\")\n",
    "\n",
    "    if ((seq_length != X.shape[1]) or (seq_length != peakPValueX.shape[1])):\n",
    "        raise Exception(\"seq_length between model and data needs to agree\")\n",
    "\n",
    "    return X, Y, peakPValueX, peakPValueY, peakBinaryX, peakBinaryY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataNormalizer(object):\n",
    "    def __init__(self, mode):\n",
    "        self.b = None\n",
    "        self.W = None\n",
    "        self.mode = mode\n",
    "        if mode not in ['ZCA', 'Z', '01', 'identity']:\n",
    "            raise ValueError(\"mode=%s must be 'ZCA', 'Z', '01', or 'identity'\" % mode)\n",
    "\n",
    "\n",
    "    def fit(self, X_orig):\n",
    "        \"\"\"\n",
    "        Learns scaling parameters on the X_orig dataset. Does not modify X_orig.\n",
    "        \"\"\"        \n",
    "        if len(X_orig.shape) != 2 and len(X_orig.shape) != 3:\n",
    "            raise ValueError(\"X must be either a 3-tensor of shape num_examples x seq_length x \\\n",
    "                               num_input_marks, or a 2-tensor of shape num_examples x num_input_marks\")\n",
    "        if self.mode == 'identity':\n",
    "            return None        \n",
    "\n",
    "        X = np.copy(X_orig)\n",
    "        num_input_marks = X.shape[-1]\n",
    "\n",
    "        # If X is a 3-tensor, reshape X such that it is a 2-tensor of shape \n",
    "        # (num_examples * seq_length) x num_input_marks. \n",
    "        if len(X.shape) == 3:    \n",
    "            X = np.reshape(X, (-1, num_input_marks))\n",
    "        \n",
    "        self.b = np.mean(X, axis=0) \n",
    "\n",
    "        X -= self.b\n",
    "\n",
    "        if self.mode == 'ZCA':\n",
    "            sigma = np.dot(X.T, X) / X.shape[0]\n",
    "            U, S, V = np.linalg.svd(sigma)\n",
    "            self.W = np.dot(\n",
    "                np.dot(U, np.diag(1 / np.sqrt(S + 1e-5))),\n",
    "                U.T)\n",
    "        elif self.mode == 'Z':\n",
    "            self.W = np.empty(num_input_marks)\n",
    "            for idx in range(num_input_marks):\n",
    "                self.W[idx] = np.std(X[:, idx])\n",
    "        elif self.mode == '01':\n",
    "            self.W = np.empty(num_input_marks)\n",
    "            for idx in range(num_input_marks):\n",
    "                self.W[idx] = np.max(np.abs(X[:, idx]))\n",
    "\n",
    "        return None            \n",
    "\n",
    "\n",
    "    def transform(self, X):\n",
    "        if len(X.shape) != 2 and len(X.shape) != 3:\n",
    "            raise ValueError(\"X must be either a 3-tensor of shape num_examples x seq_length x \\\n",
    "                               num_input_marks, or a 2-tensor of shape num_examples x num_input_marks\")\n",
    "\n",
    "        if self.mode == 'identity':\n",
    "            return X\n",
    "            \n",
    "        assert self.b is not None\n",
    "        assert self.W is not None\n",
    "\n",
    "        num_input_marks = X.shape[-1]\n",
    "        orig_shape = X.shape\n",
    "\n",
    "        if self.mode == 'ZCA':            \n",
    "            X = np.reshape(X, (-1, num_input_marks))\n",
    "            if self.W.shape[1] != X.shape[1]:\n",
    "                raise ValueError(\"When doing a ZCA transform, X and W must have the same number of columns.\")\n",
    "            X = np.dot(\n",
    "                X - self.b,\n",
    "                self.W.T)\n",
    "            X = np.reshape(X, orig_shape)\n",
    "        elif self.mode in ['Z', '01']:\n",
    "            if (len(self.b) != num_input_marks) or (len(self.W) != num_input_marks):\n",
    "                print(\"X.shape: \", X.shape)\n",
    "                print(\"b.shape: \", self.b.shape)\n",
    "                print(\"W.shape: \", self.W.shape)\n",
    "                raise ValueError(\"The shapes of X, b, and W must all share the same last dimension.\")                \n",
    "            for idx in range(num_input_marks):\n",
    "                X[..., idx] = (X[..., idx] - self.b[idx]) / self.W[idx]\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, peakPValueX, peakPValueY, peakBinaryX, peakBinaryY = load_seq_dataset()\n",
    "\n",
    "if zero_out_non_bins:\n",
    "    peakPValueX = peakPValueX * peakBinaryX\n",
    "    peakPValueY = peakPValueY * peakBinaryY \n",
    "\n",
    "def sq2p_process_X(X):\n",
    "    return X\n",
    "\n",
    "def sq2p_process_Y(Y):\n",
    "    '''mid = (SEQ_LENGTH - 1) / 2\n",
    "    mid = int(mid)\n",
    "    return Y[:, mid:mid+1, :]'''\n",
    "    return Y\n",
    "    \n",
    "    \n",
    "X = sq2p_process_X(X)\n",
    "Y = sq2p_process_Y(Y)\n",
    "peakPValueX = sq2p_process_X(peakPValueX)\n",
    "peakPValueY = sq2p_process_Y(peakPValueY)\n",
    "peakBinaryX = sq2p_process_X(peakBinaryX)\n",
    "peakBinaryY = sq2p_process_Y(peakBinaryY)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_input = \"01\"\n",
    "normalizer = DataNormalizer(scale_input)\n",
    "normalizer.fit(X)\n",
    "X = normalizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCH          = 10\n",
    "VALID_SPLIT       = 0.05\n",
    "BATCH_SIZE        = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "bin_checkpointer = ModelCheckpoint(\n",
    "    filepath=os.path.join('.', '%s-weights.hdf5'%weights_file_name), \n",
    "    verbose=1, \n",
    "    save_best_only=True)\n",
    "\n",
    "bin_earlystopper = EarlyStopping(monitor='val_loss', patience=3, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "from keras import losses\n",
    "from keras import regularizers\n",
    "from keras.constraints import min_max_norm\n",
    "from keras.constraints import Constraint\n",
    "from keras import backend as K\n",
    "def rnn_model():\n",
    "    main_input = Input(shape=(SEQ_LENGTH, len(INPUT_MARKS)), name='main_input')\n",
    "    # Noise Spectral Estimation\n",
    "    noise_gru = GRU(\n",
    "      48, \n",
    "      activation='tanh', \n",
    "      recurrent_activation='sigmoid', \n",
    "      return_sequences=True, \n",
    "      name='noise_gru'\n",
    "    )(main_input)\n",
    "\n",
    "    # Spectral Subtraction\n",
    "    denoise_input = keras.layers.concatenate([noise_gru, main_input])\n",
    "    denoise_gru = GRU(\n",
    "      96, \n",
    "      activation='tanh', \n",
    "      recurrent_activation='sigmoid', \n",
    "      return_sequences=True, \n",
    "      name='denoise_gru'\n",
    "    )(denoise_input)\n",
    "        \n",
    "    denoise_output = Dense(\n",
    "      1, \n",
    "      activation='relu', \n",
    "      name='denoise_output'\n",
    "    )(denoise_gru)\n",
    "    \n",
    "    '''\n",
    "    denoise_output = keras.layers.Conv1D(\n",
    "        filters=len(OUTPUT_MARKS),\n",
    "        kernel_size=SEQ_LENGTH,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        activation='relu'\n",
    "    )(denoise_dense)\n",
    "    '''\n",
    "\n",
    "    # Peak ? Nope\n",
    "    peak_input = keras.layers.concatenate([denoise_gru, main_input])  \n",
    "\n",
    "    peak_gru = GRU(\n",
    "      64, \n",
    "      activation='tanh', \n",
    "      recurrent_activation='sigmoid', \n",
    "      return_sequences=True, \n",
    "      name='peak_gru'\n",
    "    )(peak_input)\n",
    "    \n",
    "    peak_output = Dense(\n",
    "      1, \n",
    "      activation='sigmoid', \n",
    "      name='peak_output'\n",
    "    )(peak_gru)\n",
    "    '''\n",
    "    peak_output = keras.layers.Conv1D(\n",
    "        filters=len(OUTPUT_MARKS),\n",
    "        kernel_size=SEQ_LENGTH,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        activation='sigmoid'\n",
    "    )(peak_dense)\n",
    "    '''\n",
    "\n",
    "    model = Model(inputs=main_input, outputs=[denoise_output, peak_output])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 1001, 6)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "noise_gru (GRU)                 (None, 1001, 48)     7920        main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1001, 54)     0           noise_gru[0][0]                  \n",
      "                                                                 main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "denoise_gru (GRU)               (None, 1001, 96)     43488       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1001, 102)    0           denoise_gru[0][0]                \n",
      "                                                                 main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "peak_gru (GRU)                  (None, 1001, 64)     32064       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "denoise_output (Dense)          (None, 1001, 1)      97          denoise_gru[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "peak_output (Dense)             (None, 1001, 1)      65          peak_gru[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 83,634\n",
      "Trainable params: 83,634\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model = rnn_model()\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(loss=[losses.mean_squared_error, losses.binary_crossentropy],\n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-shape: (10000, 1001, 6)\n",
      "Y-shape: (10000, 1001, 1)\n",
      "pY-shape: (10000, 1001, 1)\n",
      "Train on 9500 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "9500/9500 [==============================] - 244s 26ms/step - loss: 0.8288 - denoise_output_loss: 0.5694 - peak_output_loss: 0.2594 - val_loss: 0.5129 - val_denoise_output_loss: 0.3201 - val_peak_output_loss: 0.1928\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.51288, saving model to ./s2s-rnn-0002-weights.hdf5\n",
      "Epoch 2/10\n",
      "9500/9500 [==============================] - 267s 28ms/step - loss: 0.4627 - denoise_output_loss: 0.2871 - peak_output_loss: 0.1756 - val_loss: 0.4508 - val_denoise_output_loss: 0.2716 - val_peak_output_loss: 0.1792\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.51288 to 0.45078, saving model to ./s2s-rnn-0002-weights.hdf5\n",
      "Epoch 3/10\n",
      "9500/9500 [==============================] - 284s 30ms/step - loss: 0.4318 - denoise_output_loss: 0.2624 - peak_output_loss: 0.1693 - val_loss: 0.4421 - val_denoise_output_loss: 0.2642 - val_peak_output_loss: 0.1779\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.45078 to 0.44210, saving model to ./s2s-rnn-0002-weights.hdf5\n",
      "Epoch 4/10\n",
      "9500/9500 [==============================] - 258s 27ms/step - loss: 0.4196 - denoise_output_loss: 0.2527 - peak_output_loss: 0.1669 - val_loss: 0.4279 - val_denoise_output_loss: 0.2530 - val_peak_output_loss: 0.1748\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.44210 to 0.42786, saving model to ./s2s-rnn-0002-weights.hdf5\n",
      "Epoch 5/10\n",
      "9500/9500 [==============================] - 231s 24ms/step - loss: 0.4068 - denoise_output_loss: 0.2424 - peak_output_loss: 0.1644 - val_loss: 0.4155 - val_denoise_output_loss: 0.2441 - val_peak_output_loss: 0.1714\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.42786 to 0.41548, saving model to ./s2s-rnn-0002-weights.hdf5\n",
      "Epoch 6/10\n",
      "9500/9500 [==============================] - 255s 27ms/step - loss: 0.3999 - denoise_output_loss: 0.2367 - peak_output_loss: 0.1632 - val_loss: 0.4224 - val_denoise_output_loss: 0.2498 - val_peak_output_loss: 0.1727\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.41548\n",
      "Epoch 7/10\n",
      "2300/9500 [======>.......................] - ETA: 2:54 - loss: 0.4056 - denoise_output_loss: 0.2387 - peak_output_loss: 0.1669"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-37542dc3e301>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m              \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNB_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m              \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVALID_SPLIT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m              batch_size=BATCH_SIZE)\n\u001b[0m",
      "\u001b[0;32m/home/ncp/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/ncp/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ncp/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ncp/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ncp/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ncp/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ncp/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ncp/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ncp/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('X-shape:',X.shape)\n",
    "print('Y-shape:',Y.shape)\n",
    "print('pY-shape:',peakBinaryY.shape)\n",
    "\n",
    "rnn_model.fit(X, [Y, peakBinaryY], \n",
    "             callbacks=[bin_checkpointer, bin_earlystopper],\n",
    "             epochs=NB_EPOCH,\n",
    "             validation_split=VALID_SPLIT,\n",
    "             batch_size=BATCH_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
